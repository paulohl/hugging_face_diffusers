<?xml version="1.0"?>
<b:Sources SelectedStyle="" xmlns:b="http://schemas.openxmlformats.org/officeDocument/2006/bibliography" xmlns="http://schemas.openxmlformats.org/officeDocument/2006/bibliography"><b:Source><b:Year>2013</b:Year><b:Volume>47</b:Volume><b:BIBTEX_Entry>article</b:BIBTEX_Entry><b:SourceType>JournalArticle</b:SourceType><b:Title>The arcade learning environment: An evaluation platform for general agents</b:Title><b:Tag>Bellemare2013</b:Tag><b:Author><b:Author><b:NameList><b:Person><b:Last>Bellemare</b:Last><b:Middle>G.</b:Middle><b:First>M.</b:First></b:Person><b:Person><b:Last>Naddaf</b:Last><b:First>Y.</b:First></b:Person><b:Person><b:Last>Veness</b:Last><b:First>J.</b:First></b:Person><b:Person><b:Last>Bowling</b:Last><b:First>M.</b:First></b:Person></b:NameList></b:Author></b:Author><b:Pages>253, 279</b:Pages><b:JournalName>Journal of Artificial Intelligence Research</b:JournalName></b:Source><b:Source><b:BIBTEX_Entry>techreport</b:BIBTEX_Entry><b:Comments>Preprint arXiv:1312.5602</b:Comments><b:SourceType>Report</b:SourceType><b:Title>Playing Atari with deep reinforcement learning</b:Title><b:Tag>Mnih2013</b:Tag><b:Author><b:Author><b:NameList><b:Person><b:Last>Mnih</b:Last><b:First>V.</b:First></b:Person><b:Person><b:Last>Kavukcuoglu</b:Last><b:First>K.</b:First></b:Person><b:Person><b:Last>Silver</b:Last><b:First>D.</b:First></b:Person></b:NameList></b:Author></b:Author><b:Year>2013</b:Year><b:ThesisType>Tech. rep.</b:ThesisType></b:Source><b:Source><b:Year>2013</b:Year><b:Volume>32</b:Volume><b:BIBTEX_Entry>article</b:BIBTEX_Entry><b:SourceType>JournalArticle</b:SourceType><b:Title>Reinforcement learning in robotics: A survey</b:Title><b:Tag>Kober2013</b:Tag><b:Author><b:Author><b:NameList><b:Person><b:Last>Kober</b:Last><b:First>J.</b:First></b:Person><b:Person><b:Last>Bagnell</b:Last><b:Middle>A.</b:Middle><b:First>J.</b:First></b:Person><b:Person><b:Last>Peters</b:Last><b:First>J.</b:First></b:Person></b:NameList></b:Author></b:Author><b:Pages>1238, 1274</b:Pages><b:JournalName>The International Journal of Robotics Research</b:JournalName><b:Number>11</b:Number></b:Source><b:Source><b:Year>2016</b:Year><b:BIBTEX_Entry>conference</b:BIBTEX_Entry><b:SourceType>ConferenceProceedings</b:SourceType><b:Title>Asynchronous methods for deep reinforcement learning</b:Title><b:Tag>Mnih2016</b:Tag><b:BookTitle>International Conference on Machine Learning (ICML)</b:BookTitle><b:Author><b:Author><b:NameList><b:Person><b:Last>Mnih</b:Last><b:First>V.</b:First></b:Person><b:Person><b:Last>Badia</b:Last><b:First>A.</b:First><b:Middle>P.</b:Middle></b:Person><b:Person><b:Last>Mirza</b:Last><b:First>M.</b:First><b:Middle>M</b:Middle></b:Person><b:Person><b:First>Grave,</b:First><b:Middle>A.</b:Middle></b:Person><b:Person><b:First>Lillicrap,</b:First><b:Middle>T</b:Middle></b:Person><b:Person><b:First>Harley,</b:First><b:Middle>T.</b:Middle></b:Person><b:Person><b:Last>Kavukcuoglu</b:Last><b:First>K.</b:First></b:Person></b:NameList></b:Author></b:Author><b:Pages>1928, 1937</b:Pages><b:ConferenceName>International Conference on Machine Learning (ICML)</b:ConferenceName><b:RefOrder>1</b:RefOrder><b:Guid>{13A69F7A-905F-4D08-9C2F-5706E5A71D26}</b:Guid></b:Source></b:Sources>
